{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cbea909",
   "metadata": {},
   "source": [
    "# Trabalho 2 - Tópicos em IA\n",
    "#### Aluno: Matheus Bernard Mota\n",
    "#### RGA: 2022.1904.008-6\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f321654a",
   "metadata": {},
   "source": [
    "\n",
    "## Eficácia de Diferentes Técnicas de Pooling na Detecção de Fake News\n",
    "\n",
    "Neste notebook, utilizaremos o modelo BERT pré-treinado em pt-br **BERTimbau** com uma camada linear para classificação.\n",
    "Para o Fine-tuning, utilizaremos o dataset de *fake-news* Fake.br corpus. A ideia é, a partir do modelo pré treinado, especializá-lo em: a partir de uma sequência (notícia), corretamente predizer se ela é verdadeira **(true)** ou falsa, **(fake)**.\n",
    "\n",
    "O código fonte foi modularizado para melhor organização, compreensão e manutenibilidade e um notebook explicativo foi posto para direcionar a execução do procedimento e análise. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01bf0ab",
   "metadata": {},
   "source": [
    "## Procedimentos Iniciais\n",
    "1. Anexar a pasta .src com este notebook, para que ele tenha acesso aos seus módulos\n",
    "2. Realizar os imports iniciais\n",
    "3. Mostra o device aceito pelo torch (#visualizações_adicionais)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10a2a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#permite importar src\n",
    "\n",
    "import os, sys\n",
    "# import sys\n",
    "\n",
    "root_relative_path = '../'\n",
    "root = os.path.abspath(root_relative_path)\n",
    "\n",
    "sys.path.append(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e11e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importa tudo aquilo que importa\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "from src.dataset_loader import DatasetLoader\n",
    "from src.custom_bertimbau_classifier import CustomBertimbauClassifier\n",
    "from src.baseline_bertimbau_classifier import BaselineBertimbauClassifier\n",
    "from src.fine_tuner import FineTuner\n",
    "import src.config as cfg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172363e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#physics are relative, but this code gonna be DETERMINISTIC BABY!\n",
    "random.seed(cfg.RANDOM_SEED) \n",
    "np.random.seed(cfg.RANDOM_SEED) \n",
    "torch.manual_seed(cfg.RANDOM_SEED)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b36f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cfg.DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c42c38",
   "metadata": {},
   "source": [
    "## Carregando o Dataset de Notícias\n",
    "\n",
    "O dataset contém 7200 notícias, com labels num ratio de ~50%\n",
    "\n",
    "#### Under the hood\n",
    "\n",
    "O que este loader está fazendo?\n",
    "1. Acessando o arquivo **pre-processed.csv** de um clone do repositório do Fake.br. (está no .gitignore, em caso de configuração local, este detalhe deve ser levado em conta)\n",
    "2. Carregando um tokenizer, proveniente do próprio bertimbau, para traduzir o texto do corpus em tokens processados \n",
    "3. Separando as colunas dos textos e suas respectivas \"labels\", ou seja, classificação da veracidade da notícia\n",
    "4. Separando, destas colunas, uma porcentagem para treino, validação(ajuste manual de parâmetros) e teste\n",
    "5. transformando estes dados em tokens e preparando um dataset anexavel ao Trainer da biblioteca Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ceb2c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(root, cfg.PATH_TO_DATASET)\n",
    "ds_loader = DatasetLoader(\n",
    "    path=path,\n",
    "    model_name=cfg.BERTIMBAU,\n",
    "    max_len=cfg.SEQ_LEN\n",
    ")\n",
    "\n",
    "#conjunto para teste, validação e treino\n",
    "train_dataset, val_dataset, test_dataset = (ds_loader\n",
    "                                            .load_dataset(seed=cfg.RANDOM_SEED)\n",
    "                                            .get_datasets())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9152d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apenas para checar se tá tudo ok\n",
    "print(train_dataset.encodings)\n",
    "print(train_dataset[0])\n",
    "print(repr(train_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd0aa11",
   "metadata": {},
   "source": [
    "## Carregando modelos BERTimbau\n",
    "\n",
    "#### **baseline_model**\n",
    "Versão do modelo onde o pooling é feito pela passagem do token **[CLS]**, presente no início de cada sentença, de modo a capturar o contexto geral de todo o documento. Este vetor é utilizado como entrada na camada de classificação.\n",
    "\n",
    "#### **alternative_model**\n",
    "Similarmente ao **baseline_model**, este modelo também aproveita do contexto capturado pelo token **[CLS]**, mas ele é concatenado com um vetor que calcula a média dos valores de todos os tokens presentes em cada sentença. Ou seja, se tenho X senteças de tamanho n  (os tamanhos variam, mas isso é regularizado com o token [PAD], que está configurado para não ser levado em consideração nas manipulações matriciais), cada i-ésimo token dos n tokens de cada sentença é somado X vezes, e uma média é retirada, divindindo o valor pelos numero de tokens significativos somados. Essa é outra forma de realizar o pooling, e garante um vetor de tamanho igual a de [CLS]. Estes dois vetores são então concatenados (dobrando o tamanho das features) e levado para a camada de classificação.\n",
    "\n",
    "$$\\text{mean\\_pooling}(\\mathbf{H}, \\mathbf{M}) = \\frac{\\sum_{i=1}^{n} \\mathbf{h}_i \\cdot m_i}{\\sum_{i=1}^{n} m_i}$$\n",
    "\n",
    "onde:\n",
    "- $\\mathbf{H}$ é a matriz de embedding\n",
    "- $\\mathbf{M}$ é a matriz de atenção, responsável por eliminar os tokens [PAD] da conta \n",
    "\n",
    "$$\\text{concat\\_pooling}(\\mathbf{H}, \\mathbf{M}) = [\\mathbf{h}_{[CLS]}; \\text{mean\\_pooling}(\\mathbf{H}, \\mathbf{M})]$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b74fcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kwargs = ds_loader.get_labels_mapping()\n",
    "\n",
    "alternative_model = CustomBertimbauClassifier(cfg.BERTIMBAU, **model_kwargs).to(cfg.DEVICE)\n",
    "baseline_model = BaselineBertimbauClassifier(cfg.BERTIMBAU, **model_kwargs).to(cfg.DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d32a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Configuraç~ao dos Modelos:\")\n",
    "print(baseline_model)\n",
    "print(\"___________________________________________\")\n",
    "print(alternative_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bd0d0a",
   "metadata": {},
   "source": [
    "## Fine tunando os modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72642456",
   "metadata": {},
   "outputs": [],
   "source": [
    "#retirado de original_script\n",
    "try:\n",
    "    acc_metric = evaluate.load(\"accuracy\")\n",
    "    f1_metric  = evaluate.load(\"f1\")\n",
    "    def compute_metrics(eval_pred):\n",
    "        logits, labels = eval_pred\n",
    "        preds = np.argmax(logits, axis=-1)\n",
    "        r1 = acc_metric.compute(predictions=preds, references=labels) #suspeito se ele vai acessar acc_metric ou nao\n",
    "        r2 = f1_metric.compute(predictions=preds, references=labels, average=\"weighted\")\n",
    "        return {\"accuracy\": r1[\"accuracy\"], \"f1\": r2[\"f1\"]}\n",
    "except Exception:\n",
    "    def compute_metrics(eval_pred):\n",
    "        logits, labels = eval_pred\n",
    "        preds = np.argmax(logits, axis=-1)\n",
    "        acc = (preds == labels).mean()\n",
    "        return {\"accuracy\": float(acc)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f46450",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fine_tuner = FineTuner(\n",
    "    tokenizer=ds_loader.get_tokenizer())\n",
    "\n",
    "tuned_baseline_res = (fine_tuner\n",
    "                        .set_compute_metrics(compute_metrics)\n",
    "                        .set_training_arguments(\n",
    "                            output_dir=os.path.join(root, \"bertimbau-baseline-cls-ptbr\"),\n",
    "                            evaluation_strategy=\"epoch\",\n",
    "                            save_strategy=\"epoch\",\n",
    "                            learning_rate=cfg.LEARNING_RATE,\n",
    "                            weight_decay=0.01,\n",
    "                            per_device_train_batch_size=cfg.BATCH_SIZE,\n",
    "                            per_device_eval_batch_size=cfg.BATCH_SIZE,\n",
    "                            num_train_epochs=cfg.NUM_EPOCHS,\n",
    "                            fp16=torch.cuda.is_available(),\n",
    "                            logging_steps=50,\n",
    "                            report_to=\"none\",\n",
    "                            seed=cfg.RANDOM_SEED\n",
    "                        )\n",
    "                        .set_trainer(\n",
    "                            model=baseline_model,\n",
    "                            train_dataset=train_dataset,\n",
    "                            eval_dataset=val_dataset\n",
    "                        )\n",
    "                        .train())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab341b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_baseline_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b68fac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#bem que eu poderia criar um método de reset\n",
    "fine_tuner = FineTuner(\n",
    "    tokenizer=ds_loader.get_tokenizer())\n",
    "\n",
    "tuned_alternative_res = (fine_tuner\n",
    "                        .set_compute_metrics(compute_metrics)\n",
    "                        .set_train_optimizer_params(lr_bert=cfg.LEARNING_RATE)\n",
    "                        .set_training_arguments(\n",
    "                            output_dir=os.path.join(root, \"bertimbau-alternativo-cls-ptbr\"),\n",
    "                            evaluation_strategy=\"epoch\",\n",
    "                            save_strategy=\"epoch\",\n",
    "                            learning_rate=cfg.LEARNING_RATE,\n",
    "                            weight_decay=0.01,\n",
    "                            per_device_train_batch_size=cfg.BATCH_SIZE,\n",
    "                            per_device_eval_batch_size=cfg.BATCH_SIZE,\n",
    "                            num_train_epochs=cfg.NUM_EPOCHS,\n",
    "                            fp16=torch.cuda.is_available(),#spoiler: nao tá -_-\n",
    "                            logging_steps=90,\n",
    "                            report_to=\"none\",\n",
    "                            seed=cfg.RANDOM_SEED\n",
    "                        )\n",
    "                        .set_trainer(\n",
    "                            model=alternative_model,\n",
    "                            train_dataset=train_dataset,\n",
    "                            eval_dataset=val_dataset\n",
    "                        )\n",
    "                        .train())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
